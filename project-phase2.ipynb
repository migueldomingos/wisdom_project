{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Phase 2: Video Dialog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#Open Search\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "#Embeddings neighborhood\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import spacy\n",
    "\n",
    "#Contextual embeddings and self-attention\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from bertviz import model_view, head_view\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import clip\n",
    "from PIL import Image\n",
    "import av\n",
    "import av.datasets\n",
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Text-based Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the video captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_captions_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    processed = {}\n",
    "    for video_id, captions in data.items():\n",
    "        processed[video_id] = {\n",
    "            \"segments\": captions['segments'] if 'segments' in captions else captions,\n",
    "        }\n",
    "    return processed\n",
    "\n",
    "# Load the data\n",
    "val_data1 = load_captions_data('captions/val_1.json')\n",
    "val_data2 = load_captions_data('captions/val_2.json')\n",
    "\n",
    "# Combine dictionaries (preserving video_id as keys)\n",
    "all_captions_data = {**val_data1, **val_data2}\n",
    "\n",
    "pprint(f\"Number of captions: {len(all_captions_data)}\")\n",
    "pprint(f\"Example Captions: {all_captions_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('activity_net.v1-3.min.json', 'r') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "database = {}\n",
    "\n",
    "for video_id in data['database']:\n",
    "    database[\"v_\" + video_id] = data['database'][video_id]\n",
    "\n",
    "# Create the list with all data, sorted by the number of annotations\n",
    "sorted_database = sorted(\n",
    "    database.items(),\n",
    "    key=lambda x: len(x[1]['annotations']),\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Top 10 videos in number of annotations\n",
    "top_videos = dict(sorted_database[:27])\n",
    "\n",
    "pprint(top_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_ids = set(database.keys()) & set(all_captions_data.keys())\n",
    "print(f\"Número de IDs correspondentes: {len(matching_ids)}\")\n",
    "print(f\"IDs no top_videos: {list(top_videos.keys())[:5]}...\")\n",
    "print(f\"IDs em all_captions_data: {list(all_captions_data.keys())[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the final captions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset_captions = {}\n",
    "#final_dataset_video = {}\n",
    "\n",
    "# Check and store the captions' of the top 10 videos\n",
    "for video_id in top_videos:\n",
    "    try:\n",
    "        if (all_captions_data[video_id] != None):\n",
    "            final_dataset_captions[video_id] = all_captions_data[video_id]\n",
    "            #final_dataset_video[video_id] = top_videos[video_id]\n",
    "    except Exception as e:\n",
    "        None\n",
    "\n",
    "final_dataset_captions.pop(\"v_PJ72Yl0B1rY\", None) # This video has no available URL\n",
    "#final_dataset_video.pop(\"v_PJ72Yl0B1rY\", None)\n",
    "\n",
    "pprint(final_dataset_captions)\n",
    "pprint(len(final_dataset_captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyframe extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_url, output_path):\n",
    "    ydl_opts = {\n",
    "        'format': 'mp4',\n",
    "        'outtmpl': output_path,\n",
    "        'quiet': True\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segment_keyframes(video_path, output_dir, t):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        with av.open(video_path) as container:\n",
    "            stream = container.streams.video[0]\n",
    "            stream.codec_context.skip_frame = \"NONKEY\"\n",
    "            time_base = stream.time_base  # Needed to convert pts to seconds\n",
    "\n",
    "            for frame in container.decode(stream):\n",
    "                timestamp_sec = frame.pts * time_base\n",
    "\n",
    "                i = 0\n",
    "                aux = math.inf\n",
    "                right_ts = -1\n",
    "\n",
    "                for s in t:\n",
    "                    # Code to find the closest timestamp \n",
    "                    start = float(s[0])\n",
    "                    end = float(s[1])\n",
    "\n",
    "                    value = abs(float(timestamp_sec) - start) + abs(float(timestamp_sec) - end)\n",
    "                    if value < aux and start <= float(timestamp_sec) <= end:\n",
    "                        aux = value\n",
    "                        right_ts = i\n",
    "                    i += 1\n",
    "\n",
    "                if t[right_ts][0] <= float(timestamp_sec) <= t[right_ts][1]:\n",
    "                    # Save the frame as an image\n",
    "                    out_path = os.path.join(\n",
    "                        output_dir,\n",
    "                        f\"frame_{float(t[right_ts][0])}_{float(t[right_ts][1])}_{round(float(timestamp_sec), 4)}.jpg\"\n",
    "                    )\n",
    "                    frame.to_image().save(out_path, quality=80)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {video_path}: {e}\")\n",
    "\n",
    "# Base folders\n",
    "video_dir = \"videos\"\n",
    "output_base = \"keyframes\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "processed_count = 0\n",
    "missing_count = 0\n",
    "\n",
    "for video_id, metadata in final_dataset_captions.items():\n",
    "    video_path = os.path.join(video_dir, f\"{video_id}.mp4\")\n",
    "    output_dir = os.path.join(output_base, video_id)\n",
    "    t = final_dataset_captions[video_id]['segments']['timestamps']\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        video_url = top_videos[video_id]['url']\n",
    "        print(f\"[Download] {video_id} → {video_url}\")\n",
    "        download_video(video_url, video_path)\n",
    "\n",
    "    if os.path.exists(video_path):\n",
    "        print(f\"[Processing] Extracting keyframes from: {video_id}\")\n",
    "        extract_segment_keyframes(video_path, output_dir, t)\n",
    "        processed_count += 1\n",
    "    else:\n",
    "        print(f\"[Missing] Could not find video after download: {video_id}\")\n",
    "        missing_count += 1\n",
    "\n",
    "print(\"\\nKeyframe extraction completed.\")\n",
    "print(f\"    Processed videos: {processed_count}\")\n",
    "print(f\"    Missing videos: {missing_count}\")\n",
    "print(f\"    Keyframes saved in: {output_base}/<video_id>/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch connection settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connections to the Open Search Server\n",
    "host = 'api.novasearch.org'\n",
    "port = 443\n",
    "\n",
    "user = 'user09'\n",
    "password = 'grupo09fct'\n",
    "index_name = user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if OpenSearch is up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = (user, password),\n",
    "    use_ssl = True,\n",
    "    url_prefix = 'opensearch_v2',\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False\n",
    ")\n",
    "\n",
    "if client.indices.exists(index_name):\n",
    "\n",
    "    resp = client.indices.open(index = index_name)\n",
    "    print(resp)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX SETTINGS')\n",
    "    settings = client.indices.get_settings(index = index_name)\n",
    "    pprint(settings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX MAPPINGS')\n",
    "    mappings = client.indices.get_mapping(index = index_name)\n",
    "    pprint(mappings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX #DOCs')\n",
    "    print(client.count(index = index_name))\n",
    "else:\n",
    "    print(\"Index does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.delete(index=index_name, ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"knn\": True\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"video_id\": {\"type\": \"keyword\"},\n",
    "            \"start_timestamp\": {\"type\": \"text\"},\n",
    "            \"end_timestamp\": {\"type\": \"text\"},\n",
    "            \"caption\": {\"type\": \"text\"},\n",
    "            \"caption_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 512,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"innerproduct\",\n",
    "                    \"engine\": \"faiss\",\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 256,\n",
    "                        \"m\": 48\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"image_clip_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 512,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"innerproduct\",\n",
    "                    \"engine\": \"faiss\",\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 256,\n",
    "                        \"m\": 48\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    print(\"Index already existed. You may force the new mappings.\")\n",
    "else:        \n",
    "    response = client.indices.create(index_name, body=index_body)\n",
    "    print('\\nCreating index:')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode images and text using CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_embedding = model.encode_image(image)\n",
    "        return image_embedding[0].cpu().numpy()\n",
    "    \n",
    "def encode_text(text):\n",
    "    text_tokens = clip.tokenize([text]).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_embedding = model.encode_text(text_tokens)\n",
    "        return text_embedding[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_clip_data(video_id, start_timestamp, end_timestamp, caption, image_path):\n",
    "    caption_vec = encode_text(caption).tolist()\n",
    "    image_vec = encode_image(image_path).tolist()\n",
    "    \n",
    "    doc = {\n",
    "        \"video_id\": video_id,\n",
    "        \"start_timestamp\": start_timestamp,\n",
    "        \"end_timestamp\": end_timestamp,\n",
    "        \"caption\": caption,\n",
    "        \"caption_vector\": caption_vec,\n",
    "        \"image_clip_vector\": image_vec\n",
    "    }\n",
    "    \n",
    "    client.index(index=index_name, body=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index the images and captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyframes_root = Path(\"./keyframes\")\n",
    "\n",
    "for video_folder in keyframes_root.iterdir():\n",
    "    video_id = video_folder.name\n",
    "\n",
    "    for img in video_folder.glob(\"*.jpg\"):\n",
    "        filename_parts = img.stem.split(\"_\")\n",
    "        start_ts = float(filename_parts[1])\n",
    "        end_ts = float(filename_parts[2])\n",
    "\n",
    "        img_path = str(img)\n",
    "\n",
    "        timestamp_array = final_dataset_captions[video_id]['segments']['timestamps']\n",
    "        sentences_array = final_dataset_captions[video_id]['segments']['sentences']\n",
    "        \n",
    "        i = timestamp_array.index([start_ts, end_ts])\n",
    "\n",
    "        sentence = sentences_array[i]\n",
    "\n",
    "        index_clip_data(video_id, start_ts, end_ts, sentence, img_path)\n",
    "\n",
    "        print(f\"Indexed: {video_id} {img_path} {timestamp_array[i]} {sentences_array[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.refresh(index=index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
